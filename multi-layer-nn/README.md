# মাল্টি লেয়ার নিউরাল নেটওয়ার্ক

আগের চ্যাপ্টারে উল্লেখ করা সমস্যাটি ছিল,

![](https://nuhil.files.wordpress.com/2017/05/screen-shot-2017-05-18-at-9-35-36-pm.png?w=687)

জটিল প্যাটার্ন খুঁজে নিতে যেমন একাধিক লেয়ার এবং নিউরনের সংখ্যা বেশি লাগবে তেমনি লাগবে বেশি পরিমাণ ট্রেনিং ডাটা। আমরা নিজেরা যেমন, কোন প্যাটার্ন বুঝতে গিয়ে প্রশ্নকর্তাকে জিজ্ঞেস করি যে আরও কয়েকটা উদাহরণ দাও, তেমনি নিউরাল নেটওয়ার্কও জটিল এবং কনফিউজিং প্যাটার্ন বুঝতে গিয়ে যত বেশি উদাহরণ পাবে তত সঠিকভাবে প্যাটার্ন চিনতে পারবে।

&lt;/strong&gt;এখানে প্যাটার্নটা হচ্ছে এরকম -ইনপুট কম্বিনেশনের তৃতীয় কলামের ভ্যালু অনর্থক এবং প্রথম দুই কলামের মধ্যে XORঅপারেশনের উপর ভিত্তি করে আউটপুট নির্ধারীত হচ্ছে। আর তাই, 1 1 0এর আউটপুট হবে 1 XOR 1 = 0.&lt;/p&gt;

এই ধরনের প্যাটার্নকে Non Linear প্যাটার্ন বলা হয়ে থাকে। কারণ এখানে ইনপুট এবং আউটপুটের মধ্যে সরাসরি কোন one-to-one রিলেশন নাই।তাই এই প্যাটার্নকে উদ্ধার করার ক্ষমতা আমাদের আগের সিঙ্গেল নিউরন নেটওয়ার্কের নাই। বরং আমাদের একটি হিডেন লেয়ার ওয়ালা ডিপ নিউরাল নেটওয়ার্ক ডিজাইন করতে হবে।

এই নতুন লেয়ারে ৪টি নিউরন থাকতে পারে যেগুলো এই নিউরাল নেটওয়ার্ককে ইনপুট কম্বিনেশন গুলো নিয়ে একটু অন্যভাবে চিন্তা করাতে সাহায্য করে। চিন্তা কি জিনিষ আগেই একবার বলা হয়ে গেছে।

![Screen Shot 2017-05-19 at 7.26.59 PM](https://nuhil.files.wordpress.com/2017/05/screen-shot-2017-05-19-at-7-26-59-pm.png)

উপরের ডায়াগ্রাম থেকে দেখা যাচ্ছে যে, Layer 1 এর আউটপুট গুলো Layer 2 এর ইনপুট হিসেবে যাচ্ছে। এভাবে আমাদের নিউরাল নেটওয়ার্ক, লেয়ার ১ এর আউটপুট এর সাথে ট্রেনিং সেট আউটপুটেরও একটা কো-রিলেশন বের করতে পারবে। নিউরনের লার্নিং এর সাথে সাথে এই দুই লেয়ারের ওয়েট অ্যাডজাস্ট করে করে এই কো-রিলেশন বাড়তে থাকবে।

বলে নেয়া ভালো, এই বিষয়টার সাথে ইমেজ রিকগনিশনের টেকনিকের মিল আছে। অর্থাৎ যদি আমরা একটি আপেলের ফটোর কথা চিন্তা করি, সেখানে কিন্তু প্রত্যেকটা পিক্সেল \(ভ্যালু\) এর সাথে বস্তুত আপেলের কোন সম্পর্ক নাই। দুইটা দুই জগতের জিনিষ। কিন্তু আবার \[কিছু পিক্সেল কম্বিনেশন\] এবং \[আপেল\] এই দুটো ফ্যাক্টরের রিলেশনশিপ আছে। অর্থাৎ উপরের নেটওয়ার্কে, প্রথম raw input এর সাথে আউটপুট এর সরাসরি কোন সম্পর্ক নাই \(এটা আমরা জানি, ধরে নিচ্ছি\) কিন্তু লেয়ার ১ এর আউটপুট তথা পিছনের কম্বিনেশনের সাথে মুল ডাটা সেটের একটা রিলেশন থাকতে পারে। আর তাই এখানে মধ্যবর্তী লেয়ারের আবির্ভাব এবং প্রয়োজনীয়তা।

> এই যে, বিভিন্ন স্টেজের মধ্যেকার কো-রিলেশনকে চেনার জন্য এবং কাজে লাগানোর জন্য এক বা একাধিক মধ্যবর্তী লেয়ারের সংযোজন, এটাকেই ডিপ লার্নিং বলে।

